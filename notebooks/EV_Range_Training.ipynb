{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c2d5375",
   "metadata": {},
   "source": [
    "# EV Range â€” preprocessing and model training\n",
    "Run cells sequentially. This notebook loads data, cleans it, creates features, trains a RandomForest baseline and saves the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "BASE = Path.cwd()\n",
    "DATA_PATH = BASE / \"data\" / \"ev_dataset.csv\"\n",
    "MODEL_DIR = BASE / \"models\"\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "print(\"BASE\", BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5feca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) cleaning function\n",
    "def _find_column(df, candidates):\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    for name in candidates:\n",
    "        key = name.lower()\n",
    "        if key in cols_lower:\n",
    "            return cols_lower[key]\n",
    "    return None\n",
    "\n",
    "def clean_data(df):\n",
    "    mapping = {}\n",
    "    battery_col = _find_column(df, ['Battery', 'Battery_Capacity_kWh', 'battery_kwh'])\n",
    "    power_col = _find_column(df, ['Power', 'Power_hp', 'Power_kW', 'Motor_Power'])\n",
    "    efficiency_col = _find_column(df, ['Efficiency', 'Efficiency_WhPerKm', 'Energy_Consumption'])\n",
    "    weight_col = _find_column(df, ['Weight', 'Weight_kg', 'Vehicle_Weight'])\n",
    "    range_col = _find_column(df, ['Range', 'Range_km', 'range_km', 'range'])\n",
    "    if battery_col: mapping[battery_col] = 'Battery_Capacity_kWh'\n",
    "    if power_col: mapping[power_col] = 'Power_hp'\n",
    "    if efficiency_col: mapping[efficiency_col] = 'Efficiency_WhPerKm'\n",
    "    if weight_col: mapping[weight_col] = 'Weight_kg'\n",
    "    if range_col: mapping[range_col] = 'Range_km'\n",
    "    if mapping:\n",
    "        df = df.rename(columns=mapping)\n",
    "    wanted = [c for c in ['Battery_Capacity_kWh','Power_hp','Efficiency_WhPerKm','Weight_kg','Range_km'] if c in df.columns]\n",
    "    if not wanted:\n",
    "        return df.copy()\n",
    "    df = df[wanted].copy()\n",
    "    for c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    df = df.dropna().drop_duplicates().reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) load & clean\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}\")\n",
    "raw = pd.read_csv(DATA_PATH)\n",
    "print('raw shape', raw.shape)\n",
    "df = clean_data(raw)\n",
    "print('cleaned shape', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) feature engineering\n",
    "if 'Battery_Capacity_kWh' in df.columns:\n",
    "    df['battery_Wh'] = df['Battery_Capacity_kWh'] * 1000.0\n",
    "if 'Efficiency_WhPerKm' in df.columns and 'battery_Wh' in df.columns:\n",
    "    df['battery_over_eff'] = df['battery_Wh'] / df['Efficiency_WhPerKm']\n",
    "if 'Battery_Capacity_kWh' in df.columns and 'Weight_kg' in df.columns:\n",
    "    df['energy_density_kWh_per_kg'] = df['Battery_Capacity_kWh'] / df['Weight_kg'].replace(0, np.nan)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac70e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) prepare train/test and preprocess numeric features\n",
    "if 'Range_km' not in df.columns:\n",
    "    raise SystemExit(\"Missing target Range_km\")\n",
    "feature_cols = [c for c in df.columns if c != 'Range_km']\n",
    "numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "print('numeric features:', numeric_cols)\n",
    "for c in numeric_cols:\n",
    "    lo, hi = df[c].quantile([0.01, 0.99])\n",
    "    df[c] = df[c].clip(lower=lo, upper=hi)\n",
    "X = df[feature_cols].copy()\n",
    "y = df['Range_km'].astype(float).copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "X_train_num = imputer.fit_transform(X_train[numeric_cols])\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_test_num = imputer.transform(X_test[numeric_cols])\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "import pandas as pd\n",
    "X_train_p = pd.DataFrame(X_train_num, columns=numeric_cols)\n",
    "X_test_p = pd.DataFrame(X_test_num, columns=numeric_cols)\n",
    "out_dir = BASE / 'data'\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "X_train_p.to_csv(out_dir / 'X_train_preprocessed.csv', index=False)\n",
    "X_test_p.to_csv(out_dir / 'X_test_preprocessed.csv', index=False)\n",
    "y_train.to_csv(out_dir / 'y_train.csv', index=False)\n",
    "y_test.to_csv(out_dir / 'y_test.csv', index=False)\n",
    "joblib.dump({'imputer': imputer, 'scaler': scaler, 'numeric_cols': numeric_cols}, MODEL_DIR / 'preprocessor.pkl')\n",
    "print('Saved preprocessed data and preprocessor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a369267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) train baseline RandomForest (small grid)\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "param_grid = {'n_estimators':[100,300], 'max_depth':[8,16,None], 'min_samples_leaf':[1,3]}\n",
    "gs = GridSearchCV(rf, param_grid, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train_p, y_train)\n",
    "best = gs.best_estimator_\n",
    "print('best params:', gs.best_params_)\n",
    "cv_mae = -cross_val_score(best, X_train_p, y_train, cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "print('Train CV MAE:', cv_mae)\n",
    "y_pred = best.predict(X_test_p)\n",
    "print('Test MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('Test RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "print('Test R2:', r2_score(y_test, y_pred))\n",
    "joblib.dump(best, MODEL_DIR / 'ev_range_model.pkl')\n",
    "print('Saved model to', MODEL_DIR / 'ev_range_model.pkl')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
